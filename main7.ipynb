{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preserve_unused_tokens=False']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from absl import flags\n",
    "sys.argv=['preserve_unused_tokens=False']\n",
    "flags.FLAGS(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in c:\\users\\yasir\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from bert-tensorflow) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading tokenization script created by the Google\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import models\n",
    "from numpy import array_equal\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from bert import tokenization\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "import re\n",
    "from functools import partial\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (256,256,3)\n",
    "trainable = False\n",
    "max_seq_length = 128\n",
    "units = 512\n",
    "embedding_dim = 768\n",
    "batch_sz = 8\n",
    "BUFFER_SIZE = 200\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8313, 100, 1024)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_feature = np.load('Image_Embeddings/Emb_feature/new_test_features/.npy')\n",
    "np.shape(img_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the picture man in black and white cap is holding up sign . And the text says: its their character not their color that matters \n",
      "\n",
      "\n",
      "8313\n"
     ]
    }
   ],
   "source": [
    "FMS = pd.read_csv(\"FMS_final.csv\")\n",
    "FMS['textNdesc'] = 'In the picture '+ FMS.gen_caption + ' And the text says: ' + FMS.text\n",
    "print(FMS.textNdesc[0], '\\n\\n')\n",
    "print(len(FMS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_img_feature = np.load('Image_Embeddings/Emb_feature/dev_test_features/final_images.npy')\n",
    "# np.shape(dev_img_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_FMS = pd.read_csv(\"FMS_final_dev.csv\")\n",
    "# dev_FMS['textNdesc'] = 'In the picture '+ dev_FMS.gen_caption + ' And the text says: ' + dev_FMS.text\n",
    "# print(dev_FMS.textNdesc[0], '\\n\\n')\n",
    "# print(len(dev_FMS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "      super(BahdanauAttention, self).__init__()\n",
    "      self.W1 = tf.keras.layers.Dense(units)\n",
    "      self.W2 = tf.keras.layers.Dense(units)\n",
    "      self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "      hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "      attention_hidden_layer = (tf.nn.tanh(self.W1(features) +\n",
    "                                          self.W2(hidden_with_time_axis)))\n",
    "\n",
    "      score = self.V(attention_hidden_layer)\n",
    "      attention_weights = tf.nn.softmax(score, axis=1)\n",
    "      context_vector = attention_weights * features\n",
    "      context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "      return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(LuongAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    values_transposed = tf.transpose(values, perm=[0, 2, 1])\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    #BAHDANAU ADDITIVE:\n",
    "    #score = self.V(tf.nn.tanh(\n",
    "    #    self.W1(query_with_time_axis) + self.W2(values)))\n",
    "    \n",
    "    #LUONGH Dot-product\n",
    "    score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed) , perm=[0, 2, 1])\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len):\n",
    "    # hidden = tf.zeros((1, 1024))\n",
    "\n",
    "    enc_hidden = tf.zeros((1, 1024))\n",
    "\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    dec_input = tf.expand_dims(clf_output, axis = 1)\n",
    "\n",
    "    # image input\n",
    "    image_input = tf.keras.Input(shape=(100,1024), name=\"image_input\")\n",
    "    encoder_fc = tf.keras.layers.Dense(1024,kernel_initializer='glorot_uniform',use_bias=False)\n",
    "    image_input_intermediate = encoder_fc(image_input)\n",
    "    image_input_intermediate = tf.nn.relu(image_input_intermediate)\n",
    "\n",
    "    # Set up the decoder layers\n",
    "    units = 1024\n",
    "    decoder_gru = tf.keras.layers.GRU(units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform') \n",
    "    decoder_fc1 = tf.keras.layers.Dense(units)\n",
    "    decoder_fc2 = tf.keras.layers.Dense(64, activation='relu', name='Dense_3_layer')\n",
    "    decoder_dropout  = tf.keras.layers.Dropout(0.3)\n",
    "    decoder_fc3  = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    # decoder layer\n",
    "    attention = BahdanauAttention(1024)\n",
    "\n",
    "    context_vector, attention_weights = attention(image_input_intermediate, enc_hidden)\n",
    "    inputs = tf.concat([tf.expand_dims(context_vector, 1), dec_input], axis=-1)\n",
    "        \n",
    "    output, state = decoder_gru(inputs)\n",
    "    decoder_fc1_output = decoder_fc1(output)\n",
    "    decoder_fc1_output = tf.reshape(decoder_fc1_output, (-1, decoder_fc1_output.shape[2]))\n",
    "    decoder_fc2_output = decoder_fc2(decoder_fc1_output)\n",
    "    decoder_dropout_output = decoder_dropout(decoder_fc2_output)\n",
    "    decoder_output = decoder_fc3(decoder_dropout_output)\n",
    "    \n",
    "    model_encoder_decoder_Bahdanau_Attention = Model([input_word_ids, input_mask, segment_ids, image_input], outputs = decoder_output, name='model_encoder_decoder')\n",
    "    model_encoder_decoder_Bahdanau_Attention.compile(Adam(lr=0.00001), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "    return model_encoder_decoder_Bahdanau_Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "model_url2 = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1\"\n",
    "bert_layer = hub.KerasLayer(model_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(FMS.textNdesc.values, tokenizer, max_len=100)\n",
    "train_labels = FMS.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_input = bert_encode(dev_FMS.textNdesc.values, tokenizer, max_len=100)\n",
    "# test_labels = dev_FMS.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_encoder_decoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 100, 1024)]  0           []                               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 100, 1024)    1048576     ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " input_word_ids (InputLayer)    [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " tf.nn.relu_3 (TFOpLambda)      (None, 100, 1024)    0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 1024),       335141889   ['input_word_ids[0][0]',         \n",
      "                                 (None, 100, 1024)]               'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      " bahdanau_attention_3 (Bahdanau  ((None, 1024),      2100225     ['tf.nn.relu_3[0][0]']           \n",
      " Attention)                      (None, 100, 1))                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 1024)        0           ['keras_layer[3][1]']            \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 1, 1024)      0           ['bahdanau_attention_3[0][0]']   \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 1, 1024)      0           ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 1, 2048)      0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.expand_dims_3[0][0]']       \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    [(None, 1, 1024),    9443328     ['tf.concat[0][0]']              \n",
      "                                 (None, 1024)]                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1, 1024)      1049600     ['gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1024)         0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " Dense_3_layer (Dense)          (None, 64)           65600       ['tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['Dense_3_layer[0][0]']          \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1)            65          ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 348,849,283\n",
      "Trainable params: 348,849,282\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "checkpoint = ModelCheckpoint('model7.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "train_history = model.fit(\n",
    "    [train_input, img_feature], train_labels,\n",
    "    validation_split=0.3,\n",
    "    epochs=100 ,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=batch_sz,\n",
    "    steps_per_epoch=12   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 4152s 16s/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model7.h5')\n",
    "test_pred = model.predict([train_input, img_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.82401700015715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "y_actual = list(train_labels)\n",
    "y_prob = list(test_pred.reshape(len(test_pred), ))\n",
    "print(\"AUC: \", roc_auc_score(y_actual, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f7660018a1f48e52e1285a6cd46b08bf9e759a1146999e72bfa769101423a7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
