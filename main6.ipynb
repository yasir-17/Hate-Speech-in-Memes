{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preserve_unused_tokens=False']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from absl import flags\n",
    "sys.argv=['preserve_unused_tokens=False']\n",
    "flags.FLAGS(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in c:\\users\\yasir\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from bert-tensorflow) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading tokenization script created by the Google\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import models\n",
    "from numpy import array_equal\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from bert import tokenization\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (256,256,3)\n",
    "trainable = False\n",
    "max_seq_length = 128\n",
    "units = 512\n",
    "embedding_dim = 768\n",
    "batch_sz = 7\n",
    "BUFFER_SIZE = 200\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8313, 100, 1024)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_feature = np.load('Image_Embeddings/Emb_feature/new_test_features/.npy')\n",
    "np.shape(img_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the picture man in black and white cap is holding up sign . And the text says: its their character not their color that matters \n",
      "\n",
      "\n",
      "8313\n"
     ]
    }
   ],
   "source": [
    "FMS = pd.read_csv(\"FMS_final.csv\")\n",
    "FMS['textNdesc'] = 'In the picture '+ FMS.gen_caption + ' And the text says: ' + FMS.text\n",
    "print(FMS.textNdesc[0], '\\n\\n')\n",
    "print(len(FMS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "      super(BahdanauAttention, self).__init__()\n",
    "      self.W1 = tf.keras.layers.Dense(units)\n",
    "      self.W2 = tf.keras.layers.Dense(units)\n",
    "      self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "      hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "      attention_hidden_layer = (tf.nn.tanh(self.W1(features) +\n",
    "                                          self.W2(hidden_with_time_axis)))\n",
    "\n",
    "      score = self.V(attention_hidden_layer)\n",
    "      attention_weights = tf.nn.softmax(score, axis=1)\n",
    "      context_vector = attention_weights * features\n",
    "      context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "      return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len):\n",
    "    # hidden = tf.zeros((1, 1024))\n",
    "\n",
    "    enc_hidden = [tf.zeros((batch_sz, 1024)), tf.zeros((batch_sz, 1024))]\n",
    "\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    dec_input = tf.expand_dims(clf_output, axis = 1)\n",
    "\n",
    "    # image input\n",
    "    # image_input = tf.keras.Input(shape=(100,1024), batch_size=None, name=\"image_input\")\n",
    "    # image_input = tf.keras.layers.Dense(1024,kernel_initializer='glorot_uniform',use_bias=False)(image_input)\n",
    "    # image_input = tf.nn.relu(image_input)\n",
    "\n",
    "    encoder_inputs = Input(shape=(100, 1024), name='encoder_inputs')\n",
    "    encoder_lstm = LSTM(1024,return_sequences=True, return_state=True,  name='encoder_lstm')\n",
    "    encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs, initial_state = enc_hidden)\n",
    "    # print(np.shape(encoder_outputs))\n",
    "    # print(np.shape(encoder_state_h))\n",
    "    # print(np.shape(encoder_state_c))\n",
    "\n",
    "    encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "    # Set up the decoder layers\n",
    "    # decoder_inputs = Input(shape=(),name='decoder_inputs')\n",
    "    decoder_lstm = LSTM(1024,  return_state=True, name='decoder_lstm')\n",
    "    # decoder_gru = tf.keras.layers.GRU(1024, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
    "    decoder_fc1 = tf.keras.layers.Dense(1024)\n",
    "    decoder_fc2 = tf.keras.layers.Dense(128, activation='relu', name='Dense_3_layer')\n",
    "    decoder_dropout = tf.keras.layers.Dropout(0.3)\n",
    "    decoder_fc3 = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')\n",
    "\n",
    "\n",
    "    all_outputs = []\n",
    "    decoder_outputs = encoder_state_h\n",
    "    states = encoder_states \n",
    "\n",
    "\n",
    "    # decoder layer\n",
    "    attention = BahdanauAttention(1024)\n",
    "\n",
    "    for _ in range(16):\n",
    "        context_vector, attention_weights = attention(encoder_outputs, decoder_outputs)\n",
    "        inputs = tf.concat([tf.expand_dims(context_vector, 1), dec_input], axis=-1)\n",
    "        \n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(inputs,initial_state=states)\n",
    "        x = decoder_fc1(decoder_outputs)\n",
    "        # print(np.shape(x))\n",
    "        # x = tf.reshape(x, (-1, x.shape[2]))\n",
    "        x = decoder_fc2(x)\n",
    "        x = decoder_dropout(x)\n",
    "        outputs = decoder_fc3(x)\n",
    "        # outputs = tf.expand_dims(outputs, 1)\n",
    "        all_outputs.append(outputs)\n",
    "        # 7. Reinject the output (prediction) as inputs for the next loop iteration\n",
    "        # as well as update the states\n",
    "        inputs = outputs\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    \n",
    "    decoder_outputs = tf.keras.layers.Average()(all_outputs)\n",
    "    \n",
    "    model_encoder_decoder_Bahdanau_Attention = Model([input_word_ids, input_mask, segment_ids, encoder_inputs], decoder_outputs, name='model_encoder_decoder')\n",
    "    model_encoder_decoder_Bahdanau_Attention.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "    return model_encoder_decoder_Bahdanau_Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "model_url2 = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1\"\n",
    "bert_layer = hub.KerasLayer(model_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(FMS.textNdesc.values, tokenizer, max_len=160)\n",
    "train_labels = FMS.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_encoder_decoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 100, 1024)]  0           []                               \n",
      "                                                                                                  \n",
      " input_word_ids (InputLayer)    [(None, 160)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 160)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 160)]        0           []                               \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(7, 100, 1024),     8392704     ['encoder_inputs[0][0]']         \n",
      "                                 (7, 1024),                                                       \n",
      "                                 (7, 1024)]                                                       \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 1024),       335141889   ['input_word_ids[0][0]',         \n",
      "                                 (None, 160, 1024)]               'input_mask[0][0]',             \n",
      "                                                                  'segment_ids[0][0]']            \n",
      "                                                                                                  \n",
      " bahdanau_attention (BahdanauAt  ((7, 1024),         2100225     ['encoder_lstm[0][0]',           \n",
      " tention)                        (7, 100, 1))                     'encoder_lstm[0][1]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[0][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[1][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[2][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[3][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[4][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[5][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[6][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[7][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[8][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[9][0]',           \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[10][0]',          \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[11][0]',          \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[12][0]',          \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[13][0]',          \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[14][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 1024)        0           ['keras_layer[0][1]']            \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[0][0]']     \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 1024)      0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (7, 1, 2048)         0           ['tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(7, 1024),          12587008    ['tf.concat[0][0]',              \n",
      "                                 (7, 1024),                       'encoder_lstm[0][1]',           \n",
      "                                 (7, 1024)]                       'encoder_lstm[0][2]',           \n",
      "                                                                  'tf.concat_1[0][0]',            \n",
      "                                                                  'decoder_lstm[0][1]',           \n",
      "                                                                  'decoder_lstm[0][2]',           \n",
      "                                                                  'tf.concat_2[0][0]',            \n",
      "                                                                  'decoder_lstm[1][1]',           \n",
      "                                                                  'decoder_lstm[1][2]',           \n",
      "                                                                  'tf.concat_3[0][0]',            \n",
      "                                                                  'decoder_lstm[2][1]',           \n",
      "                                                                  'decoder_lstm[2][2]',           \n",
      "                                                                  'tf.concat_4[0][0]',            \n",
      "                                                                  'decoder_lstm[3][1]',           \n",
      "                                                                  'decoder_lstm[3][2]',           \n",
      "                                                                  'tf.concat_5[0][0]',            \n",
      "                                                                  'decoder_lstm[4][1]',           \n",
      "                                                                  'decoder_lstm[4][2]',           \n",
      "                                                                  'tf.concat_6[0][0]',            \n",
      "                                                                  'decoder_lstm[5][1]',           \n",
      "                                                                  'decoder_lstm[5][2]',           \n",
      "                                                                  'tf.concat_7[0][0]',            \n",
      "                                                                  'decoder_lstm[6][1]',           \n",
      "                                                                  'decoder_lstm[6][2]',           \n",
      "                                                                  'tf.concat_8[0][0]',            \n",
      "                                                                  'decoder_lstm[7][1]',           \n",
      "                                                                  'decoder_lstm[7][2]',           \n",
      "                                                                  'tf.concat_9[0][0]',            \n",
      "                                                                  'decoder_lstm[8][1]',           \n",
      "                                                                  'decoder_lstm[8][2]',           \n",
      "                                                                  'tf.concat_10[0][0]',           \n",
      "                                                                  'decoder_lstm[9][1]',           \n",
      "                                                                  'decoder_lstm[9][2]',           \n",
      "                                                                  'tf.concat_11[0][0]',           \n",
      "                                                                  'decoder_lstm[10][1]',          \n",
      "                                                                  'decoder_lstm[10][2]',          \n",
      "                                                                  'tf.concat_12[0][0]',           \n",
      "                                                                  'decoder_lstm[11][1]',          \n",
      "                                                                  'decoder_lstm[11][2]',          \n",
      "                                                                  'tf.concat_13[0][0]',           \n",
      "                                                                  'decoder_lstm[12][1]',          \n",
      "                                                                  'decoder_lstm[12][2]',          \n",
      "                                                                  'tf.concat_14[0][0]',           \n",
      "                                                                  'decoder_lstm[13][1]',          \n",
      "                                                                  'decoder_lstm[13][2]',          \n",
      "                                                                  'tf.concat_15[0][0]',           \n",
      "                                                                  'decoder_lstm[14][1]',          \n",
      "                                                                  'decoder_lstm[14][2]']          \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[1][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_2[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[2][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_3[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[3][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[4][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_5[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[5][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_6[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[6][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_7[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_8 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[7][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_8[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_9 (TFOpLambda)  (7, 1, 1024)         0           ['bahdanau_attention[8][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_9[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_10 (TFOpLambda)  (7, 1, 1024)        0           ['bahdanau_attention[9][0]']     \n",
      "                                                                                                  \n",
      " tf.concat_9 (TFOpLambda)       (7, 1, 2048)         0           ['tf.expand_dims_10[0][0]',      \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_11 (TFOpLambda)  (7, 1, 1024)        0           ['bahdanau_attention[10][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_10 (TFOpLambda)      (7, 1, 2048)         0           ['tf.expand_dims_11[0][0]',      \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_12 (TFOpLambda)  (7, 1, 1024)        0           ['bahdanau_attention[11][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_11 (TFOpLambda)      (7, 1, 2048)         0           ['tf.expand_dims_12[0][0]',      \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_13 (TFOpLambda)  (7, 1, 1024)        0           ['bahdanau_attention[12][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_12 (TFOpLambda)      (7, 1, 2048)         0           ['tf.expand_dims_13[0][0]',      \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_14 (TFOpLambda)  (7, 1, 1024)        0           ['bahdanau_attention[13][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_13 (TFOpLambda)      (7, 1, 2048)         0           ['tf.expand_dims_14[0][0]',      \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_15 (TFOpLambda)  (7, 1, 1024)        0           ['bahdanau_attention[14][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_14 (TFOpLambda)      (7, 1, 2048)         0           ['tf.expand_dims_15[0][0]',      \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.expand_dims_16 (TFOpLambda)  (7, 1, 1024)        0           ['bahdanau_attention[15][0]']    \n",
      "                                                                                                  \n",
      " tf.concat_15 (TFOpLambda)      (7, 1, 2048)         0           ['tf.expand_dims_16[0][0]',      \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)                  (7, 1024)            1049600     ['decoder_lstm[0][0]',           \n",
      "                                                                  'decoder_lstm[1][0]',           \n",
      "                                                                  'decoder_lstm[2][0]',           \n",
      "                                                                  'decoder_lstm[3][0]',           \n",
      "                                                                  'decoder_lstm[4][0]',           \n",
      "                                                                  'decoder_lstm[5][0]',           \n",
      "                                                                  'decoder_lstm[6][0]',           \n",
      "                                                                  'decoder_lstm[7][0]',           \n",
      "                                                                  'decoder_lstm[8][0]',           \n",
      "                                                                  'decoder_lstm[9][0]',           \n",
      "                                                                  'decoder_lstm[10][0]',          \n",
      "                                                                  'decoder_lstm[11][0]',          \n",
      "                                                                  'decoder_lstm[12][0]',          \n",
      "                                                                  'decoder_lstm[13][0]',          \n",
      "                                                                  'decoder_lstm[14][0]',          \n",
      "                                                                  'decoder_lstm[15][0]']          \n",
      "                                                                                                  \n",
      " Dense_3_layer (Dense)          (7, 128)             131200      ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]',                  \n",
      "                                                                  'dense[2][0]',                  \n",
      "                                                                  'dense[3][0]',                  \n",
      "                                                                  'dense[4][0]',                  \n",
      "                                                                  'dense[5][0]',                  \n",
      "                                                                  'dense[6][0]',                  \n",
      "                                                                  'dense[7][0]',                  \n",
      "                                                                  'dense[8][0]',                  \n",
      "                                                                  'dense[9][0]',                  \n",
      "                                                                  'dense[10][0]',                 \n",
      "                                                                  'dense[11][0]',                 \n",
      "                                                                  'dense[12][0]',                 \n",
      "                                                                  'dense[13][0]',                 \n",
      "                                                                  'dense[14][0]',                 \n",
      "                                                                  'dense[15][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (7, 128)             0           ['Dense_3_layer[0][0]',          \n",
      "                                                                  'Dense_3_layer[1][0]',          \n",
      "                                                                  'Dense_3_layer[2][0]',          \n",
      "                                                                  'Dense_3_layer[3][0]',          \n",
      "                                                                  'Dense_3_layer[4][0]',          \n",
      "                                                                  'Dense_3_layer[5][0]',          \n",
      "                                                                  'Dense_3_layer[6][0]',          \n",
      "                                                                  'Dense_3_layer[7][0]',          \n",
      "                                                                  'Dense_3_layer[8][0]',          \n",
      "                                                                  'Dense_3_layer[9][0]',          \n",
      "                                                                  'Dense_3_layer[10][0]',         \n",
      "                                                                  'Dense_3_layer[11][0]',         \n",
      "                                                                  'Dense_3_layer[12][0]',         \n",
      "                                                                  'Dense_3_layer[13][0]',         \n",
      "                                                                  'Dense_3_layer[14][0]',         \n",
      "                                                                  'Dense_3_layer[15][0]']         \n",
      "                                                                                                  \n",
      " classifier (Dense)             (7, 1)               129         ['dropout[0][0]',                \n",
      "                                                                  'dropout[1][0]',                \n",
      "                                                                  'dropout[2][0]',                \n",
      "                                                                  'dropout[3][0]',                \n",
      "                                                                  'dropout[4][0]',                \n",
      "                                                                  'dropout[5][0]',                \n",
      "                                                                  'dropout[6][0]',                \n",
      "                                                                  'dropout[7][0]',                \n",
      "                                                                  'dropout[8][0]',                \n",
      "                                                                  'dropout[9][0]',                \n",
      "                                                                  'dropout[10][0]',               \n",
      "                                                                  'dropout[11][0]',               \n",
      "                                                                  'dropout[12][0]',               \n",
      "                                                                  'dropout[13][0]',               \n",
      "                                                                  'dropout[14][0]',               \n",
      "                                                                  'dropout[15][0]']               \n",
      "                                                                                                  \n",
      " average (Average)              (7, 1)               0           ['classifier[0][0]',             \n",
      "                                                                  'classifier[1][0]',             \n",
      "                                                                  'classifier[2][0]',             \n",
      "                                                                  'classifier[3][0]',             \n",
      "                                                                  'classifier[4][0]',             \n",
      "                                                                  'classifier[5][0]',             \n",
      "                                                                  'classifier[6][0]',             \n",
      "                                                                  'classifier[7][0]',             \n",
      "                                                                  'classifier[8][0]',             \n",
      "                                                                  'classifier[9][0]',             \n",
      "                                                                  'classifier[10][0]',            \n",
      "                                                                  'classifier[11][0]',            \n",
      "                                                                  'classifier[12][0]',            \n",
      "                                                                  'classifier[13][0]',            \n",
      "                                                                  'classifier[14][0]',            \n",
      "                                                                  'classifier[15][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 359,402,755\n",
      "Trainable params: 359,402,754\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yasir\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=160)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/12 [=>............................] - ETA: 5:52 - loss: 0.8331 - accuracy: 0.4286 - auc: 0.4583"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "checkpoint = ModelCheckpoint('model6.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "train_history = model.fit(\n",
    "    [train_input, img_feature], train_labels,\n",
    "    validation_split=0.3,\n",
    "    epochs=100 ,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=batch_sz,\n",
    "    steps_per_epoch=12   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f7660018a1f48e52e1285a6cd46b08bf9e759a1146999e72bfa769101423a7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
